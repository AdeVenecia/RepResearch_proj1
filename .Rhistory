docs <- tm_map(docs, removeNumbers)
# Remove english common stop words
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stop words as a character vector
docs <- tm_map(docs, removeWords, b)
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
# Word counts
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq=v)
head(d, 10)
# draw wordcloud
library(wordcloud)
wordcloud(words = d$word, freq = d$freq, min.freq = 1, max.words = 200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
findFreqTerms(dtm, lowfreq = 4)
# Associate between frequent terms (correlate) using findAssocs() function.
findAssocs(dtm, terms = "nike", corlimit = 0.3)
# Create a Dendrogram for the wordcloud
nike.tdm <- removeSparseTerms(dtm, sparse = 0.8)
nike.matrix <- as.matrix(nike.tdm)
distMatrix <- dist(scale(nike.matrix))
nike.fit <- hclust(distMatrix, method = "ward")
plot(nike.fit, cex=0.9, hang=-1, main="Word Cluster Dendrogram")
rect.hclust(nike.fit, k=5)
a <- getUsers(user=586730480, token=appToken)
a
a <- getUsers(user=586730480, token=appToken, private_info = TRUE)
write.csv(a, "fb_rox.csv")
uToken <- "EAACEdEose0cBAPB1se5WFddLJbefVjVlZAwdPAbaGNSXKYpMOWdOU3cTX1j5M8flE5YF939gkytpobxeceVZCWBbuikN3vhBtS2CHC0z8wkWQlmbGEM7wcoi1f3rqxIY1EllFUrgGplTAeqDhQxP9CjiGdearYrBfIfb5Aqo8FYoNUdsql"
a <- getUsers(user=586730480, token=uToken, private_info = TRUE)
write.csv(a, "fb_rox.csv")
write.csv(a, "fb_rox.csv")
rox <- getPage(user=586730480, token=uToken)
rox <- getPage(586730480, token=uToken)
library(Rfacebook)
# Text Mining
library(tm)
library(RCurl)
appid <- "1750068631951767"
appSecret <- "f7534518ab9b22b3935889e4ccfd926f"
library(Rfacebook)
fboauth <- fbOAuth(appid, appSecret, extended_permissions = TRUE)
appToken <- "1750068631951767|AUqydmUxEbwSuFgdXENMnIoMlHw"
nike_page <- getPage(page="RiteMedOfficialPage", token=appToken)
nike_post <- getPost(post=nike_page$id[1], n=50, token=appToken)
nike_message <- (nike_post$comments)$message
docs <- Corpus(VectorSource(nike_message))
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, toSpace, "'")
docs <- tm_map(docs, toSpace, "\"")
docs <- tm_map(docs,toSpace,"[^[:graph:]]")
# Convert text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stop words
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stop words as a character vector
docs <- tm_map(docs, removeWords, b)
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
# Word counts
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq=v)
head(d, 10)
# draw wordcloud
library(wordcloud)
wordcloud(words = d$word, freq = d$freq, min.freq = 1, max.words = 200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
install.packages("swirl")
install_from_swirl("Exploratory Data Analysis")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
colors()
sample(colors(),10)
pal <- colorRamp(c("red","blue"))
pal(0)
pal(1)
pal(seq(0,1,len=6))
p1 <- colorRampPalette(c("red","blue"))
p1(2)
p1(6)
0xCC
p2 <- collorRampPalette(c("red","yellow"))
p2 <- colorRampPalette(c("red","yellow"))
p2(2)
p2(10)
showMe(p1(20))
showMe(p2(20))
showMe(p2(2))
p1
?rgb
p3 <- colorRampPalette(c("blue","green"), alpha = .5)
p3(5)
plot(x,y, pch = 19, col = rgb(0,.5,.5))
plot(x,y, pch = 19, col = rgb(0,.5,.5,.3))
cols <- brewer.pal(3, "BuGn")
showMe(cols)
pal <- colorRampPalette(cols)
showMe(pal(20))
image(volcano, col = pal(20))
image(volcano, col = pal1(20))
image(volcano, col = p1(20))
str(mpg)
qplot(displ, hwy, mpg)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, color=drv, geom=c("point","smooth"))
qplot(y=hwy, data=mpg, col=drv)
qplot(y=hwy, data=mpg, color=drv)
myhigh
qplot(drv, hwy, data = mpg, geom="boxplot")
qplot(drv, hwy, data = mpg, geom="boxplot", color = manufacturer)
qplot(hwy, data=mpg, set=draw_key_vline())
qplot(hwy, data=mpg, fill=drv)
qplot(displ, hwy, data = mpg, facets = .~drv )
qplot(hwy, data = mpg, facets = drv ~ ., binwidth = 2 )
qplot(displ, hwy, data=mpg, gemo=c("point","smooth"), facets = .~drv)
qplot(displ, hwy, data=mpg, geom=c("point","smooth"), facets = .~drv)
g <- ggplot(mpg, aes(displ, hwy))
summary(g)
g+geom_point()
(g+geom_point())+geom_smooth()
g+geom_point()+geom_smooth()
g+geom_point()+geom_smooth("lm")
g+geom_point()+geom_smooth(set="lm")
g+geom_point()+geom_smooth(method="lm")
g+geom_point()+geom_smooth(method="lm")+facet_grid(.~drv)
g+geom_point()+geom_smooth(method="lm")+facet_grid(.~drv)+ggtitle("Swirl Rules!")
g+geom_point(color = "pink", size = 4, alpha = 1/2)
g+geom_point(size = 4, alpha = 1/2, aes=(color=drv))
g+geom_point(size = 4, alpha = 1/2, aes=)
g+geom_point(size = 4, alpha = 1/2)
g+geom_point(size = 4, alpha = 1/2, aes(color = drv))
g+geom_point(size = 4, alpha = 1/2, aes(color = drv))+labs(title="Swirl Rules!")+labs(x="Displacement", y="Hwy Mileage")
g+geom_point(aes(color = drv))+labs(title="Swirl Rules!")+labs(x="Displacement", y="Hwy Mileage")
g+geom_point(aes(color=drv), size=2, alpha=1/2)+geom_smooth(size=4, linetype=3, method="lm", se=FALSE)
g+geom_pint(aes(color=drv))+theme_bw(base_family="Times")
g+geom_point(aes(color=drv))+theme_bw(base_family="Times")
plot(myx,myy, type="l", ylim=c(-3,3))
g <- ggplot(testdat, aes(x=myx, y=myy))
g+geom_line()
g+geom_line()+ylim(-3,3)
g+geom_line()+coord_cartesian(ylim(c(-3,3)))
g+geom_line()+coord_cartesian(ylim(c(-3,3))
)
g+geom_line()+coord_cartesian(ylim=(c(-3,3))
g+geom_line()+coord_cartesian(ylim=(c(-3,3)))
g+geom_line()+coord_cartesian(ylim=(c(-3,3)))
g+geom_line()+coord_cartesian(ylim=(c(-3,3)))
g+geom_line()+coord_cartesian(ylim=(c(-3,3))
g + geom_line() + coord_cartesian(ylim = c(-3,3))
g <- ggplot(mpg, aes(x=dsipl,y=hwy,color=factor(year)))
g <- ggplot(mpg, aes(x=displ,y=hwy,color=factor(year)))
g+geom_point()
g+geom_point()+facet_grid(drv~cyl, margins=TRUE)
g+geom_point()+facet_grid(drv~cyl, margins=TRUE)+geom_smooth(method="lm",se=FALSE,size=2,color="black")
g+geom_point()+facet_grid(drv~cyl, margins=TRUE)+geom_smooth(method="lm",se=FALSE,size=2,color="black")+labs(x="Displacement",y="Highway Mileage", title="Swirl Rules!")
str(diamons)
str(diamonds)
qplot(price, data=diamonds)
range(diamonds$price)
qplot(price, data=diamonds,binwidth(18497/30))
qplot(price, data=diamonds,binwidth=(18497/30))
qplot(price, data=diamonds,binwidth=18497/30)
brk
couns
counts
qplot(price, data=diamonds,binwidth=18497/30, fill = cut)
qplot(price, data = diamonds, geom="density")
qplot(price, data = diamonds, geom="density", color=cut)
qplot(carat, price, data=diamonds)
qplot(carat, price, data=diamonds, shape = cut)
qplot(carat, price, data=diamonds, color = cut)
qplot(carat, price, data=diamonds, color = cut, geom_smooth(method="lm"))
qplot(carat, price, data=diamonds, color = cut) + geom_smooth(method="lm")
qplot(carat, price, data=diamonds, color = cut, facet = .~cut) + geom_smooth(method="lm")
qplot(carat, price, data=diamonds, color = cut, facets = .~cut) + geom_smooth(method="lm")
g <- ggplot(diamonds, aes(depth, price))
summary(g)
g+geom_point()
g+geom_point(alpha=1/3)
cutpoints <- quantile(diamonds$cut, seq(0,1, length=4), na.rm=TRUE)
cutpoints <- quantile(diamonds$carat, seq(0,1, length=4), na.rm=TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
g <- ggplot(diamonds, aes(depth,price))
g+geom_point(alpha=1/3)+facet_grid(cut ~ car2)
diamonds[myd,]
g+geom_point(alpha=1/3)+facet_grid(cut ~ car2)+geom_smooth(method="lm",size=3, color="pink")
ggplot(diamonds,aes(carat,price))+geom_boxplot()+facet_grid(.~cut)
dist(dataFrame)
hclust(distxy)
hc <- hclust(d=distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h=1.5, col="blue")
abline(h=.4, col="red")
5
9
12
abline(h=.05, col="green")
dist(dFsm)
hc
heatmap(dataMatrix, col=cm.colors(25))
heatmap(mt)
mt
plot(denmt)
distmt
swirl()
exit()
q
q()
library(swirl)
swirl()
swirl()
swirl()
install.packages("Exploratory Data Analysis")
install_from_swirl("Exploratory Data Analysis")
swirl()
rm(list = ls())
swirl()
swirl()
swirl()
swirl()
remove.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library("swirl")
rm(list = ls())
install_from_swirl("Exploratory Data Analysis")
swirl()
dist(dataFrame)
hc <- hclust(dist())
hc <- hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h=1.5, col="blue")
abline(h=.4, col="red")
5
12
abline(h=.05, col="green")
dist(dFsm)
hc
heatmap(dataMatrix, col=cm.colors(25))
heatmap(mt)
mt
denmt
plot(denmt)
distmt
library(shiny)
server <- function(input, output, session) {
# this will work, the reactive element is wrapped in an observer
# it prints the value to the to the results text box
observe({
updateTextInput(session, inputId = "myresults", value = input$mytext)
})
}
ui <-   basicPage(
h3("The value in the text box gets printed to the results text box."),
textInput("mytext", "Input goes here"),
textInput("myresults", "Results will be printed here", "Initial value")
)
shinyApp(ui = ui, server = server)
library(Rfacebook)
# Text Mining
library(tm)
library(RCurl)
library(wordcloud)
# Get authentication information
# https://developers.facebook.com/apps
# 'Dashboard' for information
appid <- "1750068631951767"
appSecret <- "f7534518ab9b22b3935889e4ccfd926f"
appToken <- "1750068631951767|AUqydmUxEbwSuFgdXENMnIoMlHw"
getPage("nike", token = appToken, n=10)
page <- 1
nike_post <- getPost(post=nike_page$id[page], n=as.numeric(nike_post$comments_count[page]), token=appToken)
nike_page <- getPage(page="nike", token=appToken)
page <- 1
nike_post <- getPost(post=nike_page$id[page], n=as.numeric(nike_post$comments_count[page]), token=appToken)
nike_post <- getPost(post=nike_page$id[page], n=as.numeric(nike_page$comments_count[page]), token=appToken)
nike_post
nike_post <- getPost(post=nike_page$id[page], n=10, token=appToken)
nike_post
insights <- getInsights(object_id="nike", token=appToken, metric='page_impressions')
getPage("cirrolytix", token = appToken, n=1)
insights <- getInsights(object_id="cirrolytix", token=appToken, metric='page_impressions')
uToken <- "EAAY3rZAsj2ZAcBAMxQKT6aF3zrriBqkNCVUJwK9g96ZAto9uHsvsxIVCw1hfZB6pMpGOsmK8ZCLDXxstuYXdWcHjNwb1ZBTBKPKM0wLLxLfZBqp5l8M6ZATIpyBDGV9yerEJ3VjZApg1XEdrjus0RaZAa1LKjfKm9PQ9wjXvthyrojUn0drvccIwyGn0fcPIFjM34ZD"
getPage("cirrolytix", token = uToken, n=1)
insights <- getInsights(object_id="cirrolytix", token=uToken, metric='page_impressions')
fboauth <- fbOAuth(appid, appSecret, extended_permissions = TRUE)
getLikes(user="cirrolytix", token=uToken)
getLikes(user="cirrolytix", token=appToken)
getLikes("cirrolytix", token=appToken)
getLikes("cirrolytix", token=fboauth)
getPage("cirrolytix", token = uToken, n=1)
getLikes("cirrolytix", token=fboaut)
getPage("nike", token = uToken, n=1)
getLikes(user=914100268726157, token=fboaut)
getLikes(user=914100268726157, token=uToken)
getLikes(user=914100268726157, token=appToken)
getLikes(user="914100268726157", token=appToken)
getLikes(user="914100268726157", token=uToken)
getLikes(user="914100268726157", token=fboauth)
fbOAuth <- function(app_id, app_secret, extended_permissions=FALSE, legacy_permissions=FALSE, scope=NULL)
{
## getting callback URL
full_url <- oauth_callback()
full_url <- gsub("(.*localhost:[0-9]{1,5}/).*", x=full_url, replacement="\\1")
message <- paste("Copy and paste into Site URL on Facebook App Settings:",
full_url, "\nWhen done, press any key to continue...")
## prompting user to introduce callback URL in app page
invisible(readline(message))
## a simplified version of the example in httr package
facebook <- oauth_endpoint(
authorize = "https://www.facebook.com/dialog/oauth",
access = "https://graph.facebook.com/oauth/access_token")
myapp <- oauth_app("facebook", app_id, app_secret)
if (is.null(scope)) {
if (extended_permissions==TRUE){
scope <- c("user_birthday", "user_hometown", "user_location", "user_relationships",
"publish_actions","user_status","user_likes")
}
else { scope <- c("public_profile", "user_friends")}
if (legacy_permissions==TRUE) {
scope <- c(scope, "read_stream")
}
}
if (packageVersion('httr') < "1.2"){
stop("Rfacebook requires httr version 1.2.0 or greater")
}
## with early httr versions
if (packageVersion('httr') <= "0.2"){
facebook_token <- oauth2.0_token(facebook, myapp,
scope=scope)
fb_oauth <- sign_oauth2.0(facebook_token$access_token)
if (GET("https://graph.facebook.com/me", config=fb_oauth)$status==200){
message("Authentication successful.")
}
}
## less early httr versions
if (packageVersion('httr') > "0.2" & packageVersion('httr') <= "0.6.1"){
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## httr version from 0.6 to 1.1
if (packageVersion('httr') > "0.6.1" & packageVersion('httr') < "1.2"){
Sys.setenv("HTTR_SERVER_PORT" = "1410/")
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## httr version after 1.2
if (packageVersion('httr') >= "1.2"){
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## identifying API version of token
error <- tryCatch(callAPI('https://graph.facebook.com/pablobarbera', fb_oauth),
error = function(e) e)
if (inherits(error, 'error')){
class(fb_oauth)[4] <- 'v2'
}
if (!inherits(error, 'error')){
class(fb_oauth)[4] <- 'v1'
}
return(fb_oauth)
}
install.packages("UsingR")
rm(list = ls())
library(dplyr)
library(ggplot2)
# unzip(zipfile = "actiity.zip")
data <- read.csv("activity.csv")
summary(data)
cleanData <- filter(data, !is.na(data$steps))
spI <- summarise(group_by(cleanData, interval), aveSteps = mean(steps))
spI
plot <- ggplot(spI, aes(x=interval, y=aveSteps))
plot+geom_line()
maxS <- max(spI$aveSteps)
spI[spI$aveSteps==maxS,1]
avespd <- summarise(group_by(data, date), avespd = mean(steps))
avespd
avespd <- summarise(group_by(cleandata, date), avespd = mean(steps))
avespd <- summarise(group_by(cleanData, date), avespd = mean(steps))
avespd
spI
naData <- data[is.na(data$steps)]
naData <- data[is.na(data$steps),]
subData <- merge(naData, spI, by=c("interval","aveSteps"))
naData
subData <- merge(naData, spI, by=c("interval","steps"))
?merge
avespd <- summarise(group_by(cleanData, interval), steps = mean(steps))
avespd
subData <- merge(naData, avepspd, by=c("interval","steps"))
subData <- merge(naData, avespd, by=c("interval","steps"))
subData
subData <- merge(naData, avespd, by.y = =c("interval","steps"))
subData <- merge(naData, avespd, by.y ==c("interval","steps"))
subData <- merge(naData, avespd, by=c("interval","steps"))
naData
avespd
?match
naData$steps[na.indices] <- avespd$steps[match(avespd$steps, avespd$interval)]
naData
subData <- merge(naData, avespd, by=c("interval","steps"))
subData
avespd
naData$steps[is.na(naData$steps)] <- avespd$steps[match(naData$interval, avespd$interval)][which(is.na(naData$steps))]
naData
cleanData
mergeData <- rbind(cleanData, naData)
mergeData
totalspd <- summarise(group_by(mergedata, date), Tsteps = sum(steps))
totalspd <- summarise(group_by(mergeData, date), Tsteps = sum(steps))
totalspd
hist(totalspd$Tsteps, breals = 5)
totalspd2 <- summarise(group_by(data, date), Tsteps = sum(steps))
totalspd2 <- summarise(group_by(data, date), Tsteps2 = sum(steps))
totalspd <- summarise(group_by(mergeData, date), Tsteps = sum(steps))
hist(totalspd$Tsteps, breaks = 5, col = "green")
hist(totalspd2$Tsteps2, breaks = 5, col = "red")
hist(totalspd$Tsteps, breaks = 5, col = "green")
hist(totalspd2$Tsteps2, breaks = 5, col = "red", add=T)
naData <- data[is.na(data$steps),]
aData <- data[is.na(data$steps),]
naData <- data[is.na(data$steps),]
naData
rm(list=ls())
naData <- data[is.na(),]
naData <- data[is.na(data$steps),]
setwd("C:/Users/acdev/Dropbox/Coursera/Data Science Specialization/Assignments/Course 5 Reproducible Research/Project 1/Git/RepData_PeerAssessment1")
library(dplyr)
library(ggplot2)
# unzip(zipfile = "actiity.zip")
data <- read.csv("activity.csv")
summary(data)
naData <- data[is.na(data$steps),]
totalspd <- summarise(group_by(data, date), Tsteps = sum(steps))
hist(totalspd$Tsteps, breaks = 5, col = "blue", xlab = "Steps", main = "Total Steps Daily")
meantspd <- as.integer(mean(totalspd$Tsteps))
mediantspd <- median(totalspd$Tsteps)
cleanData <- filter(data, !is.na(data$steps))
spI <- summarise(group_by(cleanData, interval), aveSteps = mean(steps))
naData$steps[is.na(naData$steps)] <- spI$steps[match(naData$interval, spI$interval)][which(is.na(naData$steps))]
naData$steps[is.na(naData$steps)] <- spI$steps[match(naData$interval, spI$interval)][which(is.na(naData$steps))]
meantspd <- as.integer(mean(totalspd$Tsteps))
rm(list=ls())
library(dplyr)
library(ggplot2)
# unzip(zipfile = "actiity.zip")
data <- read.csv("activity.csv")
# summary(data)
cleanData <- filter(data, !is.na(data$steps))
totalspd <- summarise(group_by(data, date), Tsteps = sum(steps))
hist(totalspd$Tsteps, breaks = 5, col = "blue", xlab = "Steps", main = "Total Steps Daily")
meantspd <- as.integer(mean(totalspd$Tsteps))
mediantspd <- median(totalspd$Tsteps)
meantspd
totalspd
totalspd <- summarise(group_by(cleanData, date), Tsteps = sum(steps))
meantspd <- as.integer(mean(totalspd$Tsteps))
mediantspd <- median(totalspd$Tsteps)
naData <- data[is.na(data$steps),]
naData$steps[is.na(naData$steps)] <- spI$steps[match(naData$interval, spI$interval)][which(is.na(naData$steps))]
spI <- summarise(group_by(cleanData, interval), steps = mean(steps))
naData <- data[is.na(data$steps),]
naData$steps[is.na(naData$steps)] <- spI$steps[match(naData$interval, spI$interval)][which(is.na(naData$steps))]
mergeData <- rbind(cleanData, naData)
totalspd2 <- summarise(group_by(mergeData, date), Tsteps2 = sum(steps))
hist(totalspd2$Tsteps2, breaks = 5, col = "red", xlab="Steps", main="Total Steps per Day [Fixed NAs]")
hist(totalspd$Tsteps, breaks = 5, col = "green",  add=T)
legend("topright", c("Inserted Data", "Non-NA Data"), fill=c("red", "Green") )
newMean <- as.integer(mean(totalspd2$Tsteps2))
newMedian <- median(totalspd2$Tsteps2)
mergeData$day <- weekdays(as.Date(mergeData$date))
mergeData
View(mergeData)
mergeData$dayCat <- ifelse(mergeData$day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
mergeData
spI2 <- summarise(group_by(mergeData, interval, dayCat), steps = mean(steps))
spI2
dailyp2 <- ggplot(spI2, aes(x=interval, y=steps))
dailyp2+geom_line(color="blue")+facet_grid(dayCat~., scales = "free")+xlab("Interval")+ylab("Average Steps")+ggtitle("Average Number of Steps per Interval")
